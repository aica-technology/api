"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7933],{3150:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>c,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"concepts/ros-concepts/tf","title":"TF","description":"In robotics, different components, such as sensors, actuators, and robot links, often operate in their own local","source":"@site/docs/concepts/ros-concepts/tf.md","sourceDirName":"concepts/ros-concepts","slug":"/concepts/ros-concepts/tf","permalink":"/docs/concepts/ros-concepts/tf","draft":false,"unlisted":false,"editUrl":"https://github.com/aica-technology/api/tree/main/docs/docs/concepts/ros-concepts/tf.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"TF"},"sidebar":"conceptsSidebar","previous":{"title":"Dynamic composition","permalink":"/docs/concepts/ros-concepts/dynamic-composition"},"next":{"title":"URDF","permalink":"/docs/concepts/ros-concepts/urdf"}}');var o=n(4848),r=n(8453);const a=n.p+"assets/images/tf-tree-06d112397282259d654dc8d2c154a412.png",i={sidebar_position:5,title:"TF"},c="TF in ROS",d={},l=[];function h(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"tf-in-ros",children:"TF in ROS"})}),"\n",(0,o.jsx)(t.p,{children:"In robotics, different components, such as sensors, actuators, and robot links, often operate in their own local\ncoordinate frames. One might ask questions like:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"What is the pose of an object detected by the camera relative to the robot base frame?"}),"\n",(0,o.jsx)(t.li,{children:"Where was the tracked object relative to the world frame 5 seconds ago?"}),"\n",(0,o.jsx)(t.li,{children:"Where is the end-effector relative to the environmanet?"}),"\n"]}),"\n",(0,o.jsxs)(t.p,{children:["TF, which stands for ",(0,o.jsx)(t.strong,{children:"Transform"}),", is a powerful framework designed to keep track of multiple coordinate frames and\ntheir relationship over time. It provides a standardized way to transform data between these frames, ensuring that all\nparts of the system can communicate spatial information accurately."]}),"\n",(0,o.jsx)(t.p,{children:"TF is widely adopted in ROS due to its key features:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Frame management"}),": TF maintains a dynamic tree of coordinate frames, each with a unique name (e.g. ",(0,o.jsx)(t.code,{children:"world"}),",\n",(0,o.jsx)(t.code,{children:"camera"}),", ",(0,o.jsx)(t.code,{children:"tool"}),"). The relationships between these frames are continuously updated as the robot moves or interacts\nwith its environment."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Transform Queries"}),": TF allows to query the position and orientation (transform) of any frame relative to another at\nany point in time, given that they are part of the same TF tree. This is essential for tasks like converting sensor\ndata to a common reference frame or planning robot motions."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Real-time operation"}),": TF broadcasts and listens to transforms in real time, enabling up-to-date spatial reasoning.\nThis is critical for applications such as sensor fusion, motion planning, and real-time visualization."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Time awareness"}),": TF supports time-stamped transforms, allowing you to look up the state of the system at any\nhistorical or current time. This is particularly useful for synchronizing data from multiple sensors."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Distributed system"}),": TF can operate with a central server that contains all transform information, allowing all ROS\ncomponents on any computer in the system to access the data."]}),"\n"]}),"\n",(0,o.jsx)("div",{class:"text--center",children:(0,o.jsx)("img",{src:a,alt:"Typical TF tree"})}),"\n",(0,o.jsxs)(t.p,{children:["The image above shows a typical TF tree in a simple robotic application. There are numerous coordinate frames with their\nrespective names, each with an arrow that points towards their reference frame. For instance, the transform of the\ncamera is defined in ",(0,o.jsx)(t.code,{children:"world"})," frame, as is the ",(0,o.jsx)(t.code,{children:"base"})," of the robot. The transform of the ",(0,o.jsx)(t.code,{children:"object"})," is known with respect\nto the camera and the pose of the ",(0,o.jsx)(t.code,{children:"ur_tool0"})," frame is given by successive transformations along the robot links."]}),"\n",(0,o.jsx)(t.p,{children:"To drive the robot towards the object, one needs to know where the object is relative to the robot coordinate system.\nDoing the math to chain all these transformations manually is cumbersome and prone to errors. TF provides an easy way\nto look up the transform between any two frames that are part of the same tree directly."}),"\n",(0,o.jsxs)(t.p,{children:["Transforms are defined in a ",(0,o.jsx)(t.code,{children:"geometry_msgs::msg::TransformStamped"})," message. It is stamped, meaning it has a time\nassociated with the transform. It also has a ",(0,o.jsx)(t.code,{children:"frame_id"})," that refers to the reference frame of the transform, and a\n",(0,o.jsx)(t.code,{children:"child_frame_id"}),", which is the name of the transform. Latstly, it contains the values for the translation vector and\nthe unit quaternion representing the rotation."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"header:\n  stamp:\n    sec: 1750404981\n    nanosec: 370141910\n  frame_id: base\nchild_frame_id: object\ntransform:\n  translation:\n    x: 0.250897\n    y: 0.154403\n    z: 0.097337\n  rotation:\n    x: 0.0\n    y: -0.707107\n    z: 0.707107\n    w: 0.0\n"})}),"\n",(0,o.jsx)(t.p,{children:"Understanding the concepts of TF, coordinate frames and their reference frames is crucial because it forms the foundation\nfor how spatial relationships are represented and managed in ROS-based robotic systems."}),"\n",(0,o.jsx)(t.admonition,{type:"info",children:(0,o.jsxs)(t.p,{children:["Read more about TF in\n",(0,o.jsx)(t.a,{href:"https://docs.ros.org/en/jazzy/Concepts/Intermediate/About-Tf2.html",children:"the official ROS 2 documentation"}),"."]})})]})}function m(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>i});var s=n(6540);const o={},r=s.createContext(o);function a(e){const t=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),s.createElement(r.Provider,{value:t},e.children)}}}]);