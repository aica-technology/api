"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8589],{4127:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"concepts/building-blocks/frames","title":"Frames","description":"The page on TF in ROS discusses the importance of spatial transforms for robotic applications.","source":"@site/docs/concepts/building-blocks/frames.md","sourceDirName":"concepts/building-blocks","slug":"/concepts/building-blocks/frames","permalink":"/docs/concepts/building-blocks/frames","draft":false,"unlisted":false,"editUrl":"https://github.com/aica-technology/api/tree/main/docs/docs/concepts/building-blocks/frames.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Frames"},"sidebar":"conceptsSidebar","previous":{"title":"Events","permalink":"/docs/concepts/building-blocks/events"},"next":{"title":"Components","permalink":"/docs/concepts/building-blocks/components"}}');var i=t(4848),a=t(8453);const o={sidebar_position:3,title:"Frames"},r="Frames",l={},c=[{value:"Using frames as signals",id:"using-frames-as-signals",level:2},{value:"Frame to Signal",id:"frame-to-signal",level:3},{value:"Signal to Frame",id:"signal-to-frame",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"frames",children:"Frames"})}),"\n",(0,i.jsxs)(n.p,{children:["The page on ",(0,i.jsx)(n.a,{href:"/docs/concepts/ros-concepts/tf",children:"TF in ROS"})," discusses the importance of spatial transforms for robotic applications.\nTF can be thought of as a live database that keeps track of coordinate frames and their relationships over time. The AICA\nSystem leverages this framework internally and facilitates interaction with TF. In particular, user-defined\nframes are directly included in an AICA application and are available to all components at runtime. These so-called\n",(0,i.jsx)(n.strong,{children:"application frames"})," can be created and modified in the 3D scene view, and their poses will be updated in real time."]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/docs/examples/guides/application-frames",children:"This guide"})," contains an in-depth review of methods to create, edit, and\nrecord application frames in AICA Studio."]})}),"\n",(0,i.jsx)(n.h2,{id:"using-frames-as-signals",children:"Using frames as signals"}),"\n",(0,i.jsx)(n.p,{children:"In data-flow programming, it might often be necessary to extract the pose of one specific frame from TF in real time and\npublish that information as a continuous signal."}),"\n",(0,i.jsx)(n.p,{children:"For instance, a vision component might publish the pose of a detected object to TF, while a motion generator component\nrequires the target pose to be received as a signal. Ideally, the vision component would output the pose as a signal,\nbut this is not always the case. For these situations, the AICA Core provides components that can extract the pose of a\ndesired frame from TF and publish it as a signal, or conversely, receive a pose from a signal and send it to TF."}),"\n",(0,i.jsx)(n.h3,{id:"frame-to-signal",children:"Frame to Signal"}),"\n",(0,i.jsx)(n.p,{children:"The Frame to Signal component looks up a desired frame at the specified rate and publishes it on its output as a\nCartesian pose. The component has several additional parameters to configure its behavior:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Frame"}),": defines which frame should be looked up from TF"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Reference frame"})," (optional): defines in what reference frame the frame should be expressed in, default is ",(0,i.jsx)(n.code,{children:"world"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Remap frame"})," (optional): if provided, the name of the Cartesian pose output will be set to this value"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Remap reference frame"})," (optional): if provided the reference frame of the Cartesian pose output will be set to this\nvalue"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"signal-to-frame",children:"Signal to Frame"}),"\n",(0,i.jsx)(n.p,{children:"The Signal to Frame component receives a Cartesian pose on its input and sends the information to TF at the specified\nrate. The component has two additional parameters to configure its behavior:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Remap frame"})," (optional): if provided, the name of the transform sent to TF will be set to this value"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Remap reference frame"})," (optional): if provided the reference frame of the transform sent to TF will be set to this\nvalue"]}),"\n"]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["See ",(0,i.jsx)(n.a,{href:"/docs/examples/core-components/point-attractor",children:"this page"})," for an example that uses the Frame to Signal\ncomponent in AICA Studio."]})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>r});var s=t(6540);const i={},a=s.createContext(i);function o(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);